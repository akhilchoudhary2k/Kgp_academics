# -*- coding: utf-8 -*-

"""SDM_Assignment2.ipynb
Automatically generated by Colaboratory.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install wandb -q

import torch
import torch.nn as nn
import torch.optim as optim

import torch.nn.functional as F
import torch.backends.cudnn as cudnn

import torchvision
import torchvision.transforms as transforms

import wandb
import numpy as np
import matplotlib.pyplot as plt


import wandb
wandb.login()


# check for GPU presence
if torch.cuda.is_available():    
    # use the GPU if present
    device = torch.device("cuda")
    print('There are %d GPUs' % torch.cuda.device_count())
    print('GPU in use = ', torch.cuda.get_device_name(0))
# if not present
else:
    print('No GPU is there, using the CPU.')
    device = torch.device("cpu")

########################################################################################

# Data preprocessing
print('Data transformation')
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(
    trainset, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(
    root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(
    testset, batch_size=100, shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')

############################################################################################


# Load the model and set the desired configuration parameters
def configure(opt, lr, momentum, freeze ):

  net = torchvision.models.resnet18(pretrained = True)
  feature_count = net.fc.in_features

  # remove last fc layer
  net.fc = nn.Linear(feature_count, 10)                       
  net = net.to(device)
  learning_rate = lr
  # criterion = nn.CrossEntropyLoss()
  
  if freeze == True:
    # freeze all layers except the last fc layer
    for name, param in net.named_parameters():
      # if not the last one freeze it
      if not 'fc' in name:
          param.requires_grad = False
  
  if opt == "sgd":
    optimizer = torch.optim.SGD( net.parameters(), lr=learning_rate, momentum = momentum )
  
  elif opt == "adam":
    optimizer = torch.optim.Adam( net.parameters(), lr=learning_rate)
  
  return net, optimizer, nn.CrossEntropyLoss()


############################################################################################

# Training
def train(epoch_num):
    train_loss = 0
    net.train()

    print('\n======= Epoch = %d of 200 =======' % epoch_num )

    for inputs, targets in trainloader:
        inputs, targets = inputs.to(device), targets.to(device)
        # Write your code here

        # forward pass
        outputs = net(inputs)
        # loss computation
        loss = criterion(outputs, targets)
        train_loss+=(loss.item()) 

        optimizer.zero_grad()
        # backpropagation
        loss.backward()
        # updating the weights
        optimizer.step()

    train_loss/= len(trainloader)
    print("> Train loss   = ",train_loss)
    
    # log the training loss
    wandb.log({"Training Loss": train_loss})

############################################################################################

# Testing
def test(epoch_num):
    net.eval()

    with torch.no_grad():
      # initialization
      sample_imgs = []
      test_loss = 0
      correct = 0
      total = 0

      for inputs, targets in testloader:
          inputs, targets = inputs.to(device), targets.to(device)
          
          outputs = net(inputs)
          test_loss += criterion(outputs, targets).item()
          predicted = torch.max(outputs.data, 1)[1]
          total += targets.size(0)
          correct += (predicted == targets).sum().item()
          sample_imgs.append(wandb.Image(inputs[0], caption="Pred: {} Truth: {}".format(predicted[0].item(), targets[0])))

      # test loss computation
      test_loss/= len(testloader)
      # test accuracy computation
      test_acc = (100*correct)/total
      test_acc = round(test_acc, 3)

      print("> Test loss    = ",test_loss)
      print("> Test accuracy= ",test_acc)

      wandb.log({"Test Loss": test_loss, "Test Accuracy": test_acc, "Example Images": sample_imgs})
      
      return test_loss

############################################################################################

def run_model(pth, early_stop_count = 5):
  
  # initialization
  loss = 0
  retry = 0
  best_loss = float('inf')

  wandb.watch(net, log="all")
  
  # iterate for 200 epochs
  for epoch in range(200):

      train(epoch)
      loss = test(epoch)

      # if current loss is better then update the best_loss
      if best_loss > loss:
        best_loss = loss
        retry = 0
        torch.save(net.state_dict(), pth)

      else:
        retry+=1
        if retry == early_stop_count:
          print("\n[Early stopping]\n")
          break


############################################################################################


def make_confusion_matrix(pth):
  # initialization
  conf_mat = np.zeros([10,10], int)                                  
  correct = 0
  total = 0
  # acc = []
  net.load_state_dict(torch.load(pth))
  net.eval()


  with torch.no_grad():
      for inputs,targets in testloader:
          inputs, targets = inputs.to(device),targets.to(device)
          
          outputs = net(inputs)
          pred = torch.max(outputs.data, 1)[1]
          
          total += targets.size(0)
          correct += (pred == targets).sum().item()

          # filling the matrix
          for x, y in enumerate(targets):
              conf_mat[y.item(), pred[x].item()] += 1
  
  # plotting it
  fig, ax = plt.subplots(1,1,figsize=(8,6))
  ax.matshow(conf_mat,cmap=plt.get_cmap('Blues'))
  
  for (i, j), z in np.ndenumerate(conf_mat):
      ax.text(j, i, '{}'.format(z), ha='center', va='center')
  
  plt.ylabel('Actual Category :')
  plt.yticks(range(10), classes)
  plt.xlabel('Rred Category :')
  plt.xticks(range(10), classes)
  plt.show()

  # best and worst classification details:
  mx = 0
  mn = float('inf')

  for x in range(10):
    if conf_mat[x][x] > mx:
      mx = conf_mat[x][x]
      maxc = classes[x]

    if conf_mat[x][x] < mn:
      mn = conf_mat[x][x]
      minc = classes[x]

  print("Worst identified class = ",minc, "\n\n")
  print("Best identified class  = ",maxc)
  print("\n\nModel Accuracy     = {}%".format((100*correct)/total))



# Running the model on the 4 configurations given in assignment


# part A ===================================================================
# train all layers
# SGD optimizer with  learning_rate = 0.001, momentum = 0.9 and loss function = cross-entropy

wandb.init(project="SDM_Assignment_2", entity = 'akhilchoudhary')
config = wandb.config
config.optimizer = "sgd"

# set the configurations
config.lr = 0.001
config.momentum = 0.9
config.freeze = False

net,optimizer,criterion = configure(config.optimizer,config.lr,config.momentum,config.freeze)

# run the model
run_model("model1.pth")

# confusion matrix plot
make_confusion_matrix("model1.pth")



# part B ===================================================================
# train all layers
# Adam optimizer with learning_rate = 0.01 and loss function = cross-entropy

wandb.init(project="SDM_Assignment_2", entity = 'akhilchoudhary')
config = wandb.config
config.optimizer = "adam"
config.freeze = False
config.momentum = 0.9
config.lr = 0.01
net,optimizer,criterion = configure(config.optimizer,config.lr,config.momentum,config.freeze)

run_model("model2.pth")
make_confusion_matrix("model2.pth")



# part C =================================================
# Freeze the other layers and finetune only the last layer
# SGD optimizer with  learning_rate = 0.001, momentum = 0.9 and loss function = cross-entropy


wandb.init(project="SDM_Assignment_2", entity = 'akhilchoudhary')
config = wandb.config
config.optimizer = "sgd"
config.freeze = True
config.momentum = 0.9
config.lr = 0.001
net,optimizer,criterion = configure(config.optimizer,config.lr,config.momentum,config.freeze)

run_model("model3.pth",10)
make_confusion_matrix("model3.pth")



# part D =================================================
# Freeze the other layers and finetune only the last layer
# Adam optimizer with learning_rate = 0.01 and loss function = cross-entropy

wandb.init(project="SDM_Assignment_2", entity = 'akhilchoudhary')
config = wandb.config
config.optimizer = "adam"
config.freeze = True
config.momentum = 0.9
config.lr = 0.01
net,optimizer,criterion = configure(config.optimizer,config.lr,config.momentum,config.freeze)

run_model("model4.pth",10)
make_confusion_matrix("model4.pth")


